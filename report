在本次實作中，系統性地比較了以 TF-IDF 為代表的傳統自然語言處理方法與以 GPT-4o 為代表的現代大型語言模型，在文本相似度、分類與自動摘要三項任務上的效能表現。
從效能數據來看，TF-IDF 的執行時間穩定在毫秒等級，展現了演算法在效率上的絕對優勢。這種基於詞頻統計的方法，其運算過程完全透明，具備高度的可解釋性，且無須任何外部依賴，適合部署於對延遲敏感或資源受限的環境，然而其核心限制在於無法理解語義。從分類任務的結果可以清楚看到，對於「好吃」這類需語境理解的詞彙，或「AI」與「科技」這類概念性關聯，TF-IDF 完全無法處理，導致其準確率存在明顯的上限。在摘要任務上，其抽取式的設計本質也導致產出的連貫性與重點掌握度不佳。
相比之下，GPT-4o 展現了強大的語義理解與生成能力，它無需預先定義的特徵或規則，僅透過零樣本學習就能完美完成分類任務，並能進行流暢的生成式摘要，將原文核心思想以更精煉的人話重新表述。這種能力來自於其在大規模資料上預訓練所得的語言模型。然而，此能力的代價是高昂的計算成本與延遲。每次 API 呼叫都伴隨著一定的等待時間與成本，且其決策過程如同黑盒子。
在實作層面上，開發 TF-IDF 解決方案如同進行「特徵工程」，必須手動設計關鍵詞庫、設計句子評分機制，並處理文本前處理中的各種邊界案例。而 GPT-4o 則更像是進行「系統整合」，挑戰重心轉移至提示工程的精確度、API 的穩定性、錯誤處理機制，以及如何將非結構化的模型輸出穩定地整合進後續流程中。
一個可行的系統設計理想的設計是讓兩種方法「分工合作」，形成一個兩階段的處理流程：第一階段，由 TF-IDF 進行快速篩選，任務是從資料海中，迅速找出所有「可能有關」的候選名單。第二階段，再由 GPT-4o 進行深度分析，只對前面得到的候選名單進行深度語義分析和智慧生成。如此一來既保有了傳統方法處理大數據的「效率」，又能精準發揮大型模型的「智慧」，可謂是一種雙贏的策略。



