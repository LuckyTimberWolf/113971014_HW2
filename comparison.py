# -*- coding: utf-8 -*-
"""comparison.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jh8mFr93kuIafjFd2yWd_LKE9C0NZt60
"""

from google.colab import drive
drive.mount('/content/drive')

import sys

# 專案檔案所在的「絕對路徑」
project_path = '//content/drive/MyDrive/113971014_HW2'


# 檢查是否已經在路徑中，如果沒有，就加入它
if project_path not in sys.path:
    sys.path.append(project_path)

import traditional_methods  # 導入所有傳統方法
import modern_methods  # 導入所有現代方法
import time
import pandas as pd
import json

# --- 測試資料 ---
DOCUMENTS_A1 = [ # 相似度測試
    "人工智慧正在改變世界,機器學習是其核心技術",
    "深度學習推動了人工智慧的發展,特別是在圖像識別領域",
    "今天天氣很好,適合出去運動",
    "機器學習和深度學習都是人工智慧的重要分支",
    "運動有益健康,每天都應該保持運動習慣"
]

TEST_TEXTS_A2 = [ # 分類測試
    "這家餐廳的牛肉麵真的太好吃了,湯頭濃郁,麵條Q彈,下次一定再來!",
    "最新的AI技術突破讓人驚艷,深度學習模型的表現越來越好",
    "這部電影劇情空洞,演技糟糕,完全是浪費時間",
    "每天慢跑5公里,配合適當的重訓,體能進步很多"
]
# 假設的真實標籤 (用於計算準確率)
TRUE_LABELS = {
    'sentiment': ['正面', '正面', '負面', '正面'],
    'topic': ['美食', '科技', '其他', '運動']
}

ARTICLE_A3 = """
人工智慧(AI)的發展正在深刻改變我們的生活方式。從早上起床時的智慧鬧鐘,
到通勤時的路線規劃,再到工作中的各種輔助工具,AI無處不在。
在醫療領域,AI協助醫生進行疾病診斷,提高了診斷的準確率和效率。透過分析
大量的醫療影像和病歷資料,AI能夠發現人眼容易忽略的細節,為患者提供更好
的治療方案。
教育方面,AI個人化學習系統能夠根據每個學生的學習進度和特點,提供客製化
的教學內容。這種因材施教的方式,讓學習變得更加高效和有趣。
然而,AI的快速發展也帶來了一些挑戰。首先是就業問題,許多傳統工作可能會
被AI取代。其次是隱私和安全問題,AI系統需要大量數據來訓練,如何保護個人
隱私成為重要議題。最後是倫理問題,AI的決策過程往往缺乏透明度,可能會產
生偏見或歧視。
面對這些挑戰,我們需要在推動AI發展的同時,建立相應的法律法規和倫理準則。
只有這樣,才能確保AI技術真正為人類福祉服務,創造一個更美好的未來。
"""



import traditional_methods  # 導入所有傳統方法
import modern_methods  # 導入所有現代方法
import time
import pandas as pd
import json
import os #
import matplotlib.pyplot as plt # 繪圖
import seaborn as sns # 美化圖表

def calculate_accuracy(predictions, truths):
    """計算準確率"""
    correct = sum(1 for p, t in zip(predictions, truths) if p == t)
    return (correct / len(truths)) * 100 if truths else 0

def run_performance_test():
    """執行所有任務並收集量化指標"""
    metrics = {
        'TF-IDF': {},
        'GPT-4o': {}
    }

    # 確保 'results' 目錄存在 (放在所有文件操作之前)
    if not os.path.exists('results'):
        os.makedirs('results')

    # ------------------ 相似度計算比較 (A-1 vs B-1) ------------------
    print("--- 執行相似度計算比較 ---")

    # 傳統方法 (假設使用 sklearn 實作，計時)
    start_time_tf = time.time()
    sim_tf, feature_names_tf = traditional_methods.sklearn_tfidf_similarity(DOCUMENTS_A1) # 修正函數名稱，並獲取 feature_names
    end_time_tf = time.time()
    metrics['TF-IDF']['sim_time'] = end_time_tf - start_time_tf
    metrics['TF-IDF']['sim_cost'] = 0 # 完全免費
    metrics['TF-IDF']['sim_accuracy'] = "?%"

    # 儲存 TF-IDF 相似度矩陣圖
    plt.figure(figsize=(8, 6))
    sns.heatmap(sim_tf, annot=True, cmap='Blues', fmt=".2f",
                xticklabels=[f"Doc{i+1}" for i in range(len(DOCUMENTS_A1))],
                yticklabels=[f"Doc{i+1}" for i in range(len(DOCUMENTS_A1))])
    plt.title('TF-IDF Similarity Matrix')
    plt.savefig('results/tfidf_similarity_matrix.png')
    plt.close() # 關閉圖表以釋放記憶體

    # 現代方法 (僅計算其中一組，計時和成本估算)
    start_time_ai = time.time()
    sim_ai = modern_methods.ai_similarity(DOCUMENTS_A1[0], DOCUMENTS_A1[3])
    end_time_ai = time.time()
    metrics['GPT-4o']['sim_time'] = end_time_ai - start_time_ai
    metrics['GPT-4o']['sim_cost'] = "$0.001?" # 實際費用需要查閱 OpenAI 定價
    metrics['GPT-4o']['sim_accuracy'] = "?%"

    # ------------------ 文本分類比較 (A-2 vs B-2) ------------------
    print("\n--- 執行文本分類比較 ---")

    # 傳統方法
    sentiment_classifier = traditional_methods.RuleBasedSentimentClassifier()
    topic_classifier = traditional_methods.TopicClassifier()
    traditional_sentiments = []
    traditional_topics = []
    start_time_tf_cls = time.time()
    for text in TEST_TEXTS_A2:
        traditional_sentiments.append(sentiment_classifier.classify(text))
        traditional_topics.append(topic_classifier.classify(text))
    end_time_tf_cls = time.time()

    sent_acc_tf = calculate_accuracy(traditional_sentiments, TRUE_LABELS['sentiment'])
    topic_acc_tf = calculate_accuracy(traditional_topics, TRUE_LABELS['topic'])
    metrics['TF-IDF']['cls_time'] = end_time_tf_cls - start_time_tf_cls
    metrics['TF-IDF']['cls_accuracy'] = f"{round((sent_acc_tf + topic_acc_tf)/2, 2)}%"

    # 現代方法
    ai_sentiments = []
    ai_topics = []
    start_time_ai_cls = time.time()
    for text in TEST_TEXTS_A2:
        result = modern_methods.ai_classify(text)
        ai_sentiments.append(result.get('sentiment'))
        ai_topics.append(result.get('topic'))
    end_time_ai_cls = time.time()

    sent_acc_ai = calculate_accuracy(ai_sentiments, TRUE_LABELS['sentiment'])
    topic_acc_ai = calculate_accuracy(ai_topics, TRUE_LABELS['topic'])
    metrics['GPT-4o']['cls_time'] = end_time_ai_cls - start_time_ai_cls
    metrics['GPT-4o']['cls_accuracy'] = f"{round((sent_acc_ai + topic_acc_ai)/2, 2)}%"

    # 儲存分類結果到 CSV
    classification_data = {
        'Text': TEST_TEXTS_A2,
        'True_Sentiment': TRUE_LABELS['sentiment'],
        'TFIDF_Sentiment': traditional_sentiments,
        'GPT4o_Sentiment': ai_sentiments,
        'True_Topic': TRUE_LABELS['topic'],
        'TFIDF_Topic': traditional_topics,
        'GPT4o_Topic': ai_topics
    }
    df_classification = pd.DataFrame(classification_data)
    df_classification.to_csv('results/classification_results.csv', index=False, encoding='utf-8-sig')

    # ------------------ 自動摘要比較 (A-3 vs B-3) ------------------
    print("\n--- 執行自動摘要比較 ---")

    # 傳統方法
    summarizer = traditional_methods.StatisticalSummarizer()
    start_time_tf_sum = time.time()
    summary_tf = summarizer.summarize(ARTICLE_A3, ratio=0.3)
    end_time_tf_sum = time.time()
    metrics['TF-IDF']['sum_time'] = end_time_tf_sum - start_time_tf_sum
    metrics['TF-IDF']['sum_info_retention'] = "?%"
    metrics['TF-IDF']['sum_coherence'] = "?分"

    # 現代方法
    start_time_ai_sum = time.time()
    summary_ai = modern_methods.ai_summarize(ARTICLE_A3, max_length=150)
    end_time_ai_sum = time.time()
    metrics['GPT-4o']['sum_time'] = end_time_ai_sum - start_time_ai_sum
    metrics['GPT-4o']['sum_info_retention'] = "?%"
    metrics['GPT-4o']['sum_coherence'] = "?分"

    print("\n--- 原始文章 ---")
    print(ARTICLE_A3)
    print("\n--- 統計式摘要 ---")
    print(summary_tf)
    print("\n--- AI 摘要 ---")
    print(summary_ai)

    # 儲存摘要比較到 TXT 檔案
    with open('results/summarization_comparison.txt', 'w', encoding='utf-8') as f:
        f.write("--- 原始文章 ---\n")
        f.write(ARTICLE_A3)
        f.write("\n\n--- 統計式摘要 ---\n")
        f.write(summary_tf)
        f.write("\n\n--- AI 摘要 ---\n")
        f.write(summary_ai)

    # 儲存量化指標到 JSON 檔案
    with open('results/performance_metrics.json', 'w', encoding='utf-8') as f:
        json.dump(metrics, f, ensure_ascii=False, indent=4)

    return metrics

if __name__ == '__main__':
    # 運行測試，將實際結果填入比較表 (C-1)
    results = run_performance_test()
    print("\n--- 量化比較結果 (JSON 格式) ---")
    print(json.dumps(results, ensure_ascii=False, indent=4))